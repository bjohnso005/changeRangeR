#===================================================================
#===================================================================
#===================================================================
#' @title Collapse columns of a sparse matrix
#' @description
#' @param
#' @param
#' @param
#' @param
#' @param
#' @param
#' @param
#' @param
# @examples
#
#' @return
#' @author Cory Merow <cory.merow@@gmail.com>
#' @note optionally uses an attribute table to subset by each column not called `species` or `index` and creates a richness file based on the name of the attribute table column. the attribute table must include the species and index columns, as generated by `speciesIndexTable`
# @seealso
# @references
# @aliases - a list of additional topic names that will be mapped to
# this documentation when the user looks them up from the command
# line.
# @family - a family name. All functions that have the same family tag will be linked in the docum
#' @export

collapseCols=function(inDir,
                      outDir,
                      scenario,
                      spAttrTable,
                      attrName,
                      type='binary',
                      keepChunks=F,
                      mc.cores=mc.cores,
                      overwrite=F,
                      verbose=T){
  ## for testing
  ## attrTable=genusSpAttr; attrName='genus'; scenario='present'; inDir=sumDirs$cbsDir; outDir=sumDirs$cbgDir; keepChunks=F

  t1=proc.time()
  message(paste0('starting ',scenario))
  cbs.f=changeRangeR:::.getCBS(inDir,scenario)
  if(Sys.info()["sysname"]== "Windows") mclapply=parallelsugar::mclapply
  if(Sys.info()["sysname"]!= "Windows") mclapply=parallel::mclapply

  anames=unique(spAttrTable[,attrName]) %>% na.omit
  message(paste(length(anames), 'groups to aggregate over'))
  out=mclapply(seq_along(cbs.f), function(x){
    if(verbose) message(x)
    out.f=paste0(outDir,'/chunk_',x,'.rds')
    if(file.exists(out.f) & !overwrite) {
    	message(paste('chunk',x,'done, skipping'))
    	return()
    }
    cbs.tmp=readRDS(cbs.f[x])
    colByName=lapply(seq_along(anames),function(y){
      keep=which(spAttrTable[,attrName]==anames[y])
      if(length(keep)==1) return(cbs.tmp[,keep])
      o=cbs.tmp[,keep] %>% textTinyR::sparse_Sums(rowSums = T)
      if(type=='binary') return(o %>% pmin(1))
      if(type=='count') return(o)
    }) # returns the cols of the cbs matrix where each is collapsed to a unique attribute name
    sp.mat=do.call(cbind,colByName) %>% Matrix::Matrix(sparse=T)
    rownames(sp.mat)=rownames(cbs.tmp)
    colnames(sp.mat)=anames
    if(keepChunks) saveRDS(sp.mat,file=paste0(outDir,'/chunk_',x,'.rds'))
    sp.mat
  },mc.cores=mc.cores)
  if(!keepChunks){
    out1=do.call(rbind,out)
    saveRDS(out1,file=paste0(outDir,'/chunk_all.rds'))
  }

  t2=proc.time()-t1
  message( paste0(round(t2[3],2),' s') )
  return()
}

#===================================================================
#===================================================================
#===================================================================
#' @title Collapse rows of a sparse matrix
#' @description
#' @param indir string; path to directory with CBS matrices
#' @param outDir string; path to directory where you want to store new CBSmatrices
#' @param scenario 
#' @param colSubset vector of indices of columns to keep. Useful when you want to take only a subset of taxa before collapsing rows. Default `NULL` keep all columns.
#' @param cellAttrTable Note that cellAttrTable needs to have a column with chunkID so you know which chunks need to be read in for each value to collapse over
#' @param colSubset numeric vector of column indices (corresponding to taxa) to keep from the columns of a CBS matrix. Default is NULL, which retains all columns (taxa). It helps to use your species index table to determine these indices. 
#' @param
#' @param
#' @param
#' @param
#' @param
# @examples
# NOT WORKING, JUST THE GIST OF IT
# cr=collapseRows(inDir=inDir,outDir=outDir,scenario=scenario,
# 	cellAttrTable=cell.ind,attrName='cellID_r2',colSubset=keep.sp, type='binary',keepChunks=F,mc.cores=mc.cores,verbose=T)
# (t2=proc.time()-t1)
# cell.ind2=cellIndexTable(targetGrid,nCellChunks=1)
# saveRDS(cell.ind2,file='/Users/ctg/Dropbox/Projects/Collaborations/Danillos_ExtremeClades/cellIndexTable.rds')
# rich=data.frame(cellID=as.numeric(rownames(aa)), rich=textTinyR::sparse_Sums(aa, rowSums = T))
# cell.ind2a=cell.ind2 %>% left_join(rich,by='cellID')
# 
# rich.r=plotCellInd(cell.ind2a,'rich',targetGrid)

#' @return
#' @author Cory Merow <cory.merow@@gmail.com>
#' @note optionally uses an attribute table to subset by each column not called `species` or `index` and creates a richness file based on the name of the attribute table column. the attribute table must include the species and index columns, as generated by `speciesIndexTable`
# @seealso
# @references
# @aliases - a list of additional topic names that will be mapped to
# this documentation when the user looks them up from the command
# line.
# @family - a family name. All functions that have the same family tag will be linked in the docum
#' @export
#' @importFrom rlang .data
collapseRows=function(inDir,
                      outDir=NULL,
                      scenario,
                      cellAttrTable,
                      attrName,
                      type='binary',
                      keepChunks=F,
                      colSubset=NULL, 
                      mc.cores=mc.cores,
                      verbose=F){
# general function to snap my matrix to any grid
# if new map is coarser, just ask which coarse cell the center of each small cell occurs in.
# get cell.ind with new grid mapping
# loop over unique new grid values and aggregate
# make values >1 =1
# combine chunks 
  
  ## for testing
  ## cellAttrTable=cellAttr; attrName='ecoregion'; scenario='present'; inDir=sumDirs$cbsDir; outDir=sumDirs$cbgDir; keepChunks=F; type='binary'

  t1=proc.time()
  if(Sys.info()["sysname"]== "Windows") mclapply=parallelsugar::mclapply
  if(Sys.info()["sysname"]!= "Windows") mclapply=parallel::mclapply
  message(paste0('starting ',scenario))
  cbs.f=changeRangeR:::.getCBS(inDir,scenario)
  # just look at the ones that are relevant for the aggregating factor
	hasCellsInAttrName=cellAttrTable[which(!is.na(cellAttrTable[,attrName])), 'chunkID'] %>% unique %>% sapply(function(x) grep(paste0('chunk_',x,'.rds'),cbs.f)) %>% unlist
	cbs.f=cbs.f[hasCellsInAttrName]
	# cell IDs (or other grouping factor) of the cell attribute given by attrName
  cellIDAttr=unique(cellAttrTable[,attrName]) %>% na.omit %>% sort
  
  out=mclapply(seq_along(cbs.f), function(x){
    if(verbose) message(paste0('CBS chunk ',x))
    cbs.tmp=readRDS(cbs.f[x])
    if(!is.null(colSubset)) cbs.tmp=cbs.tmp[,colSubset]
    # the unique cell ids of just the attrName in this chunk
    thisChunkID=sub('chunk_','',cbs.f[x] %>% basename %>% file_path_sans_ext) %>% as.numeric
    # faster way to do this with mutliplication https://slowkow.com/notes/sparse-matrix/

    thisChunk_cellIDAttr=cellAttrTable %>% filter(chunkID==thisChunkID) %>% dplyr::select(cellID,{{attrName}}) %>% filter(complete.cases(.)) %>% arrange(desc({{attrName}}))
		cbs.sub=cbs.tmp[which(rownames(cbs.tmp) %in% thisChunk_cellIDAttr$cellID),]
		asFactor=factor(thisChunk_cellIDAttr[,attrName])
    mat=model.matrix(~0+asFactor)
    sp.mat=t(t(cbs.sub) %*% mat)
    if(type=='binary') sp.mat=sp.mat %>% pmin(1)
    rownames(sp.mat)=levels(asFactor)
    colnames(sp.mat)=colnames(cbs.sub)
    
    # #old way looping over cells
		#     thisChunk_cellIDAttr=cellAttrTable %>% filter(chunkID==thisChunkID) %>% dplyr::select({{attrName}}) %>% na.omit %>% unique %>% pull({{attrName}}) %>% sort
		# 	# shouldn't be needed because we used hasCells above...	
		# 	# 		if(length(thisChunk_cellIDAttr)==0){ # no cells in this chunk 
		# 	# 			sp.mat=rep(0,ncol(cbs.tmp)) %>% Matrix::Matrix(sparse=T)
		# 	# 		} else {
		# 		# combine matrix by rows
		# 		rowByName=lapply(seq_along(thisChunk_cellIDAttr),function(y){
		# 			# make sure to get the cellID (not just the row number from the attribute table)
		# 			keepIndex=cellAttrTable %>% filter(.data[[attrName]]==thisChunk_cellIDAttr[{{y}}]) %>% pull(cellID)
		# 			keep=which(keepIndex %in% as.numeric(rownames(cbs.tmp)))
		# 			#keep=cellAttrTable[which(cellAttrTable[,attrName]==cellIDAttr[y]), 'cellID']
		# 			#keep.in.this.chunk=which(keep %in% as.numeric(rownames(cbs.tmp)))
		# 			# when you collapse spatially reference them  based on the cell attribute table, where there's a field linking the (e.g.) ecoregion ID to the row name of the ecoregion by species matrix
		# 			if(length(keep)==0) { return(rep(0,ncol(cbs.tmp)))}
		# 			if(length(keep)==1) { return(cbs.tmp[keep,])}
		# 			o=cbs.tmp[keep,] %>% textTinyR::sparse_Sums(rowSums = F) 
		# 			if(type=='binary') o=o %>% pmin(1)
		# 			return(o)
		# 		}) # returns the cols of the cbs matrix where each is collapsed to a unique attribute name
		# 		sp.mat=do.call(rbind,rowByName) %>% Matrix::Matrix(sparse=T)
		# 		#}
		#     rownames(sp.mat)=thisChunk_cellIDAttr
		#     colnames(sp.mat)=colnames(cbs.tmp)
				#if(keepChunks) saveRDS(sp.mat,file=paste0(outDir,'/chunk_',x,'.rds'))
    sp.mat
  },mc.cores=mc.cores)
  # combine spatial units which are split across CBS chunks. basically repeat the same logic used within a chunk above now among chunks 
	# do.call can't handle a large number of rows quickly but can handle subsets and then rbind them for some reason. 
	t1=proc.time()
	chunks=.chopTasks(1:length(out),mc.cores)
	fuck=mclapply(seq_along(chunks),function(y){		
		do.call(rbind,out[chunks[[y]]])
	},mc.cores=mc.cores)
	out1=do.call(rbind,fuck)
	(t2=proc.time()-t1)
	#rm(out); rm(fuck); gc()
	
	asFactor2=factor(rownames(out1))
	mat2=model.matrix(~0+asFactor2) %>% Matrix::Matrix(sparse=T)
	t1=proc.time()
	chunks2=.chopTasks(1:ncol(out1),mc.cores) 
	fuck2=mclapply(seq_along(chunks2),function(y){		
		aa=t(t(out1[,chunks2[[y]]]) %*% mat2)
		if(type=='binary') aa=aa %>% pmin(1)
	},mc.cores=mc.cores)
	#sp.mat2=t(t(out1) %*% mat2)
	forFucksSake=do.call(cbind,fuck2) %>% Matrix::Matrix(sparse=T)
	rownames(forFucksSake)=levels(asFactor2)
	(t2=proc.time()-t1)
	# rm(out)

	# old way looping over unique cell IDs
	# # 	out2=mclapply(seq_along(cellIDAttr),function(y){
	# # 		if(verbose) print(y)
	# # 		(keep=which(rownames(out1)==cellIDAttr[y]))
	# # 		if(length(keep)==1) { return(out1[keep,] %>% Matrix::Matrix(sparse=T,nrow=1))}
	# # 		o=out1[keep,] %>% textTinyR::sparse_Sums(rowSums = F) %>% Matrix::Matrix(nrow=1,sparse=T)
	# # 		if(type=='binary') o= o %>% pmin(1)
	# # 		o
	# # 	},mc.cores=mc.cores) 
	# # 	chunks=.chopTasks(1:length(out2),mc.cores)
	# # 	# do.call can't handle a large number of rows quickly
	# # 	fuck=mclapply(1:mc.cores,function(y){		
	# # 		do.call(rbind,out2[chunks[[y]]])
	# # 	},mc.cores=mc.cores)
	# # 	sp.mat=do.call(rbind,fuck)
	
	# # 	rownames(sp.mat)=cellIDAttr
	# # 	cbs.tmp=readRDS(cbs.f[1]) # to get colnames
	# #   if(!is.null(colSubset)) cbs.tmp=cbs.tmp[,colSubset]
	# # 	colnames(sp.mat)=colnames(cbs.tmp)
	
  if(!is.null(outDir)) saveRDS(forFucksSake, file=paste0(outDir,'/chunk_all.rds'))
  t2=proc.time()-t1
  message( paste0(round(t2[3],2),' s') )
  return(forFucksSake)
}

#=========================================================================
# OLD - was this even used or working?
# # collapseRows=function(inDir,
# #                       outDir,
# #                       scenario,
# #                       cellAttrTable,
# #                       attrName,
# #                       type='binary',
# #                       keepChunks=F,
# #                       mc.cores=mc.cores,
# #                       verbose=F){
# #   ## for testing
# #   ## cellAttrTable=cellAttr; attrName='ecoregion'; scenario='present'; inDir=sumDirs$cbsDir; outDir=sumDirs$cbgDir; keepChunks=F; type='binary'
# # 
# #   t1=proc.time()
# #   message(paste0('starting ',scenario))
# #   cbs.f=changeRangeR:::.getCBS(inDir,scenario)
# #   if(Sys.info()["sysname"]== "Windows") mclapply=parallelsugar::mclapply
# #   if(Sys.info()["sysname"]!= "Windows") mclapply=parallel::mclapply
# # 
# #   anames=unique(cellAttrTable[,attrName]) %>% na.omit
# #   out=mclapply(seq_along(cbs.f), function(x){
# #     if(verbose) message(x)
# #     cbs.tmp=readRDS(cbs.f[x])
# #     rowByName=lapply(seq_along(anames),function(y){
# #       # make sure to get the cellID (not just the row number from the attribute table)
# #       keep=cellAttrTable[which(cellAttrTable[,attrName]==anames[y]),'cellID']
# #       keep.in.this.chunk=which(keep %in% as.numeric(rownames(cbs.tmp)))
# #       # when you collapse spatially reference them  based on the cell attribute table, where there's a field linking the (e.g.) ecoregion ID to the row name of the ecoregion by species matrix
# #       if(length(keep.in.this.chunk)==0) { return(rep(0,ncol(cbs.tmp)))}
# #       o=cbs.tmp[keep.in.this.chunk,] %>% textTinyR::sparse_Sums(rowSums = F)
# #       if(type=='binary') return(o %>% pmin(1))
# #       if(type=='count') return(o)
# #     }) # returns the cols of the cbs matrix where each is collapsed to a unique attribute name
# #     sp.mat=do.call(rbind,rowByName) %>% Matrix::Matrix(sparse=T)
# #     not0=which(apply(sp.mat,1,sum)>0)
# #     #if(all(null.attrs)) return(NULL)
# #     rownames(sp.mat)=anames
# #     colnames(sp.mat)=colnames(cbs.tmp)
# #     # probably a bad option because the same spatial unit can be distributed across a few chunks
# #     if(keepChunks) saveRDS(sp.mat,file=paste0(outDir,'/chunk_',x,'.rds'))
# #     sp.mat
# #   },mc.cores=mc.cores)
# #   # need to combine spatial units which are split across chunks. just use reduce, because all the output matrices should be the same size
# #   out1=Reduce('+',out)
# # 
# #   if(!keepChunks){
# #     saveRDS(out1,file=paste0(outDir,'/chunk_all.rds'))
# #   }
# # 
# #   t2=proc.time()-t1
# #   message( paste0(round(t2[3],2),' s') )
# #   return()
# # }


#unfinished first try to be deleted when the real thing works
# cbsCollapseCells=function(cbsDir,scenario,cellAttr,attrName,verbose=F){
#
#   t1=proc.time()
#   message(paste0('starting ',scenario))
#   cbs.f=changeRangeR:::.getCBS(cbsDir,scenario)
#   if(Sys.info()["sysname"]== "Windows") mclapply=parallelsugar::mclapply
#   if(Sys.info()["sysname"]!= "Windows") mclapply=parallel::mclapply
#   attrs=unique(cellAttr[,attrName])
#
#   richByFact=mclapply(seq_along(cbs.f), function(fu){
#     if(verbose) message(fu)
#     cbs.tmp=readRDS(cbs.f[fu])
#     # 1. split CBS by factor
#     a=cellAttr %>% filter(chunkID==fu)
#     ua=unique(a[,attrName]) %>% na.omit
#     if(length(ua)==0) return(NULL)
#     # 2. colSums within factor
#     cbs %>% mutate(cellID=row.names(cbs)) %>% left_join(cellAttr,by='cellID') %>%
#       group_by(ecoregion) %>% summarize(somethingAboutColSums) %>% somethingToMakeSparseAgain
#     # make a sparse matrix where the rows are the factor values and cols are species
#     out=lapply(ua,function(xx){
#       cid=cellAttr %>% filter(.data[[attrName]]==xx) %>% select(cellID)
#       # match cellIDs to the rowNames of cbs
#       keep=which(as.integer(row.names(cbs.tmp)) %in% cid[,1])
#       out=textTinyR::sparse_Sums(cbs.tmp[keep,], rowSums = F)
#       # 3. convert to binary with vals > 0
#       out[out>0]=1 #there's probably a faster way
#       out
#     }) %>% data.frame
#     names(out)=ua
#     out
#   },mc.cores=mc.cores)
#   # 4. combine across cbs
#   str(richByFact)
#   richByFact %>% reduce(bind_rows)
#   richByFact %>% bind_rows
#
#   out=Reduce('+',richByFact) %>% as.matrix %>% as.data.frame
#   names(out)=names(someStack)
#   out=data.frame(sp.ind,out)
#   # 5. row sums for richness (or any other operation on these reduced factor by species (FBS) matrices)
#   data.frame(cellID=as.numeric(rownames(cbs)),rich=textTinyR::sparse_Sums(cbs, rowSums = T))
#
# }
